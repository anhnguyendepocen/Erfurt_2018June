---
title: "Sales Data - Case Study Answers"
author: "BaselRBootcam April 2018"
output: html_document
---

```{r, echo = FALSE}
knitr::opts_chunk$set(comment=NA, fig.width=6, fig.height=6, echo = TRUE, eval = TRUE)
```


### Overview

In this case study, we will look at sales data from a retailer. There are two datasets, one called "sales.csv", and one called "stores.csv". You will first perform some data wrangling and merge the two datasets and then save the merged dataset as "retailer_sales.csv". Below you find two tables with the variable names and a short description of each variable of the two datasets. After that you will have the oportunity to "pick your adventure" and do the analysis you like. For example, you could check how large the fluctuations of sales are per store, or whether sales numbers go up or down in holidays, how well you can predict sales numbers from the other variables, e.g. using a regression, or you could run a time series analysis to predict future turnovers. For each of these suggestions you will find a short paragraph that provides some guidance and hints to what you could do, but feel free to play with the dataset as you wish. Because there are multiple timepoints per store involved, we will often have to either aggregate the data over these, or will not be able to interpret p-values. One method to address this issue is by using mixed effects models. This is rather advanced and we will not cover it here. However, if you are familiar with the method and want to give it a try in R, you can use the `lmer` function from the `lme4` package.



| Variable| Description|
|:------------------------------|:----------------------------------------------------------------|
|     Store|    Numeric Id of each of the stores|
|     DayOfWeek|    A number representing the day of the week| 
|     Date|    The date|
|     Sales|    The turnover on a given day|
|     Customers|    The number of costumers on a given day|
|     Open|    Whether the store was open (1) or closed (0) on a given day| 
|     Promo|   Whether a store was running a promo that day|
|     StateHoliday|  Whether there where (NA) or were no (0) state holidays that day.|
|     SchoolHoliday|  If the store on a given date was affected by the closure of public schools (1) or not (0)|

Table: Table1. "sales.csv" variable description:


| Variable| Description|
|:------------------------------|:----------------------------------------------------------------|
|     Store|    Numeric Id of each of the stores|
|     Assortment|  What level of assortment a given store has. Can be basic, extra, or extended|
|     CompetitionDistance|  The distance in meters to the nearest competitor store|
|     CompetitionOpenSinceMonth|  The month of the year in which the nearest competitor opened  |
|     CompetitionOpenSinceYear|  The year when the nearest competitor opened  |
|     Promo2|  Wheter a store is participating (1) or not (2) in a continuing and consecutive promotion for some stores|
|     Promo2SinceWeek|  The week of the year in which the store promotion started|
|     Promo2SinceYear|  The year in which the store promotion started|
|     PromoInterval|  Describes the consecutive intervals Promo2 is started, naming the months the promotion is started anew. For example, "Feb,May,Aug,Nov" means each round starts in February, May, August, November of any given year for that store|

Table: Table 2. "stores.csv" variable description:


### Data I

1. Open a new R script and save it as a new file called `sales_case_study.R`. At the top of the script, using comments, write your name and the date. Then, load the `tidyverse`package. Here's how the top of your script should look:

```{r, eval = TRUE, echo = TRUE, message = FALSE, warning = FALSE}
## NAME
## DATE
## Sales Data - Case Study

library(tidyverse)

```




2. Load in the "sales.csv", and "stores.csv" datasets from your data folder.


```{r, eval=FALSE, message = FALSE, warning = FALSE}
# Load data from your local data file of your R project

sales <- read_csv("data/sales.csv")
stores <- read_csv("data/stores.csv")

```

```{r, eval=TRUE, echo=FALSE, message = FALSE, warning = FALSE}
# Load data from your local data file of your R project

sales <- read_csv("https://raw.githubusercontent.com/therbootcamp/therbootcamp.github.io/master/_sessions/_data/sales.csv")
stores <- read_csv("https://raw.githubusercontent.com/therbootcamp/therbootcamp.github.io/master/_sessions/_data/stores.csv")

```


3. Get a first impression of the datasets by looking at a few rows of them. 

```{r}
# Get to know the data
head(sales)
str(sales)

head(stores)
str(stores)

```

### Data Wrangling

4. From the stores data, only select the following variables: Store, Assortment, CompetitionDistance, CompetitionOpenSinceYear, Promo2. The variable Assortment contains the values "a", "b", and "c". This is not very helpful. Change them so that "a" is now "basic", "b" is now "extra", and "c" is now "extended".

```{r}
stores <- stores %>%
  select(Store, Assortment, CompetitionDistance, CompetitionOpenSinceYear, Promo2) %>%
  mutate(Assortment = case_when(Assortment == "a" ~ "basic",
                                Assortment == "b" ~ "extra",
                                Assortment == "c" ~ "extended"))

```

5. Join the stores data with the sales data (check out the `left_join()` function for this).

```{r}
sales <- left_join(sales, stores, by = "Store")
```

6. The sales data contains an error in the state_holiday variable. There are `NA`s where there should be `1`s. Change this (remember that `variable == NA` won't yield the result you want; use `is.na(variable)` instead).

```{r}
sales <- sales %>%
    mutate(StateHoliday = case_when(is.na(StateHoliday) ~ 1,
                                   TRUE ~ 0))
```

7. Rename the variables to be lower case and with underscores between words. Afterwards your variables should be named like this: "store", "week_day", "date", "sales", "customers", "open", "promo", "state_holiday", "school_holiday", "assortment", "competition_distance", "competition_open_since", and "store_promo".

```{r}
names(sales) <- c("store", "week_day", "date", "sales", "customers", "open",
                  "promo", "state_holiday", "school_holiday", "assortment",
                  "competition_distance", "competition_open_since","store_promo")
```

### Data O

8. Save the prepared data as "retailer_sales.csv" (this is easy to do with the `write_csv()` function).

```{r}
write_csv(sales, "retailer_sales.csv")
```

### Statistics

#### Flucutations over Days

To look at the average fluctuations over days you, we suggest you take a subsample of a few stores. You could then plot the individual trajectories, and if you like also add a mean line. You can also use a repeated measures test, to have a statistical test of the stability (you could, for example, use a correlation between two timepoints, or aggregate sales data of stores for each timepoint and run a regression. Note that with these two methods you will violate the assumption of independence of the data, so you cannot interpret the p-value).

9. Run the following code to get a visual impression of how large the fluctuations are.

```{r, eval=TRUE, echo=TRUE, message=FALSE, warning=FALSE}

# first create a variable called "days" that is a counter
# for the number of days and will be easier to use than
# the date variable
store_ids <- unique(sales$store)
sales$days <- 0

for (i in store_ids){
  sales$days[sales$store == i] <- seq_len(sum(sales$store == i))
}

# take a subsample to plot
sales_sub <- sales[sales$store %in% sample(1:1115, 30),]

# get rid of dates where the stores were closed
sales_sub <- filter(sales_sub, sales > 0)


### Create a plot using ggplot:

ggplot(sales_sub, aes(x = days, y = sales)) + # specify the data
  geom_line(aes(group = store), col = "grey", alpha = .4) + # add line per store
  stat_smooth(lwd = 1.5) +  # add an average line
  theme_bw()                # theme for white plotting window
```


10. Randomly sample two timepoints (use the `sample()` function for this) from the `days` variable created above, and run a correlation. 

```{r, message=FALSE, warning=FALSE}

# correlation between two of the timepoints
r_ds <- sample(sales$days, 2)

cor(sales$sales[sales$days == r_ds[1]], sales$sales[sales$days == r_ds[2]])

```

11. Summarise the sales data over `days` (i.e. for each day, take the mean), and store this as an object called `sales_agg`. Then run a regression (the function to run a regression is `lm()`).

```{r, message=FALSE, warning=FALSE}

# regression

# first summarise the data
sales_agg <- sales %>%
  group_by(days) %>%
  summarise(
    sales = mean(sales)
  )

# then run regression
mod <- lm(sales ~ days, data = sales_agg)

summary(mod)


```

12. Compute the coefficient of variation, i.e. the standard deviation scaled on the mean (use the `sd()` function and divide by the `mean()`), of each stores turnovers (`sales` variable). You can do this by using `dplyr`'s `summarise()` function. Store this as an object called `sales_cv`, with the variable `cv`. Only use days on which the stores were open to not introduce extra noise (use `filter()` for this).

```{r, message=FALSE, warning=FALSE}

# regression

# first summarise the data
sales_cv <- sales %>%
  filter(open != 0) %>%
  group_by(store) %>%
  summarise(
    cv = sd(sales) / mean(sales)
  )

```

13. Plot the distribution of the coefficient of variation using the following code:

```{r, echo=TRUE, message=FALSE, warning=FALSE}

ggplot(sales_cv, aes(cv)) +  # the data to plot
  geom_histogram() +         # function to create a histogram
  xlim(c(0, 1)) +            # range of the x-axis
  xlab("Coefficient of Variation") + # x-axis title
  ylab("Frequency") +        # y-axis title
  theme_bw()                 # white theme (white plotting window)

```

#### Sales numbers in holidays

14. To test the effects of state holidays, filter the dataset to only include dates on which the given store was open. Then, average the sales of the holiday days and the non holiday days for each store (use `group_by()` and `summarise()`).




```{r, message=FALSE, warning=FALSE}
### For state holidays

# aggregate data to do the statistical test
sales_agg <- sales %>%
  filter(open != 0) %>%
  group_by(store, state_holiday) %>%
  summarise(
    sales = mean(sales)
  )

# check the means
tapply(sales_agg$sales, sales_agg$state_holiday, mean)

# get rid of stores that weren't open on any state holiday
sales_agg <- sales_agg %>%
  filter(store %in% store[state_holiday == 1])

# check the means again
tapply(sales_agg$sales, sales_agg$state_holiday, mean)
```

15. Run a paired t-test to test whether sales numbers on state holidays differ from sales numbers on normal days.


```{r, message=FALSE, warning=FALSE}

# run a paired t.test
t.test(sales ~ state_holiday,
       data = sales_agg,
       paired = TRUE)

```

16. Now repeat tasks 14. and 15. for school holidays

```{r, message=FALSE, warning=FALSE}
### Now let's do the same for school holidays

# aggregate data to do the statistical test
sales_agg <- sales %>%
  filter(open != 0) %>%
  group_by(store, school_holiday) %>%
  summarise(
    sales = mean(sales)
  )

# check the means
tapply(sales_agg$sales, sales_agg$school_holiday, mean)

# get rid of stores that weren't open on any state holiday
sales_agg <- sales_agg %>%
  filter(store %in% store[school_holiday == 1])

# check the means again
tapply(sales_agg$sales, sales_agg$school_holiday, mean)

# run a paired t.test
t.test(sales ~ school_holiday,
       data = sales_agg,
       paired = TRUE)


```


#### Predict sales numbers from other variables

To not violate the independence assumption you will have to aggregate the sales data of each store over the different time periods. You can then run a linear regression.

17. Aggregate the sales numbers over days. Include the following groups to later be used as predictors: "store", "customers", "store_promo", "competition_distance", and "assortment".

```{r, message=FALSE, warning=FALSE}

# Aggregate data
sales_agg <- sales %>%
  filter(open != 0) %>%
  group_by(store, customers, store_promo, competition_distance, assortment) %>%
  summarise(
    sales = mean(sales)
  )
```

18. Run a regression to test the influence of the variables included in task 17.

```{r, message=FALSE, warning=FALSE}

# run a regression model
mod <- lm(sales ~ .,
          data = sales_agg)
summary(mod)

```


#### Extra

Because we have repeated measures in the data, we always had to aggregate before we could run a statistical test. Using mixed effects models, this would not have been necessary, because there you can account for the dependent structure of the data with random effects. Covering the method itself is beyond the scope of this course, but if you already know the method and want to try it out, here is a code example of how you could do this. The most often used package for mixed effects modeling in R is called `lme4` with the `lmer()` function for linear mixed effects models, and the `glmer()` function for generalized mixed effects models.

```{r, echo = TRUE, eval = FALSE, message=FALSE, warning=FALSE}

# load the package
library(lme4)

# run a linear mixed effects model

# lmer uses the same syntax as lm, the regression function you already know:
# a + between two fixed effects means a main effect, a * means a main
# effect AND interaction, a : means an interaction. Thus the following
# are the same:

lm(dependent_var ~ predictor_1 + predictor_2 + predictor_1 : predictor_2)
lm(dependent_var ~ predictor_1 * predictor_2)

# mixed effects model syntax
me_mod <- lmer(dependent_var ~ fixed_eff_1 + fixed_eff_2 +
                 (random_eff_slopes | random_eff_intercept),
               data = your_dataset)


```

Here is an example for a mixed effects model you could run with the sales data that takes the same predictors we've used in task 18, but this time we use the unaggregated data and add the days variable as a random effect with varying intercepts (note that for a real analysis you'd probably want to rescale some variables and make sure all the labels make sense. But this here is just to show you how in principle you can run a mixed effects model in R.

```{r, echo = TRUE, eval = TRUE, message=FALSE, warning=FALSE}
library(lme4)

# first get rid of days where stores were closed
sales_open <- sales %>%
  filter(open != 0)

me_mod <- lmer(sales ~ customers + store_promo + competition_distance +
                 assortment + (1 | store),
               data = sales_open)

summary(me_mod)

```






