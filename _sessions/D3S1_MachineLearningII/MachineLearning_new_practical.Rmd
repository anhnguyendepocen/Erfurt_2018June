---
title: "Machine Learning"
author: "The R Bootcamp @ Erfurt<br/><a href='https://therbootcamp.github.io'>www.therbootcamp.com</a><br/><a href='https://twitter.com/therbootcamp'>@therbootcamp</a>"
output: html_document
---

```{r, echo = FALSE, fig.align = 'center', out.width = "50%", fig.cap = "The almighty Caret!"}
knitr::include_graphics("https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2014/09/Caret-package-in-R.png")
```


```{r, echo = FALSE, message = FALSE}
knitr::opts_chunk$set(comment=NA, fig.width=6, fig.height=6, echo = FALSE, eval = FALSE, fig.align = 'center')
library(tidyverse)
```


### Overview

In this practical you'll use the `caret` (**C**lassification **A**nd **RE**gression **T**raining) package to automate many aspects of the machine learning process. By the end of this practical you will know:

1. Select different 'learners' available in the `caret` package
2. Fit parameters of a learner to a dataset
3. Explore learners to understand how they work
4. Use cross validation techniques to estimate the accuracy of a learner and find best fitting parameters
5  Make predictions and evaluate the performance of learners!

### Cheatsheet

<a href="https://github.com/rstudio/cheatsheets/raw/master/caret.pdf">
  <img src="https://github.com/therbootcamp/Erfurt_2018June/blob/master/_sessions/_image/caret_cheatsheet_ss.jpg?raw=true" width="600px">
</a>

### Packages

|Package| Installation|
|:------|:------|
|`tidyverse`|`install.packages("tidyverse")`|
|`caret`|`install.packages("caret")`|
|`mlr`|`install.packages("mlr")`|
|`GGally`|`install.packages("GGally")`|

### Datasets

```{r, eval = TRUE, message = FALSE, eval = FALSE}
library(tidyverse)

house_train <- read_csv("../_data/house_train.csv")
house_test <- read_csv("../_data/house_test.csv")

heartdisease_train <- read_csv("../_data/heartdisease_train.csv")
heartdisease_train <- read_csv("../_data/heartdisease_test.csv")

attrition_train <- read_csv("../_data/attrition_train.csv")
attrition_train <- read_csv("../_data/attrition_test.csv")
```

|File | Rows | Columns | Criterion | Source |
|:----|:-----|:------|:----|:-----|
|`house_train.csv` | 1000, 15000 | 21 |`price`|[Kaggle: House Sales Prediction](https://www.kaggle.com/harlfoxem/housesalesprediction/home) |
|`house_test.csv` | 15000 | 21 | `price` |[Kaggle: House Sales Prediction](https://www.kaggle.com/harlfoxem/housesalesprediction/home) |
|`heartdisease_train.csv` | 150 | 14 |`diagnosis` | [UCI ML Heartdisease](https://archive.ics.uci.edu/ml/datasets/Heart+Disease) |
|`heartdisease_test.csv` | 150 | 14 | `diagnosis` |[UCI ML Heartdisease](https://archive.ics.uci.edu/ml/datasets/Heart+Disease) |
|`attrition_train` | 500 | 35 |`Attrition` |[Kaggle Attrition](https://www.kaggle.com/pavansubhasht/ibm-hr-analytics-attrition-dataset) |
|`attrition_test` | 900 | 35 |`Attrition` |[Kaggle Attrition](https://www.kaggle.com/pavansubhasht/ibm-hr-analytics-attrition-dataset) |


### Examples

The following set of example code will take you through the basic steps of machine learning using the amazing `caret` package.

```{r, echo = TRUE, eval = FALSE, results = 'hide', message = FALSE}
# Load packages
library(tidyverse)
library(GGally)
library(skimr)
library(caret)

# ------------------------------------
# Step 0: Create training and test data
# ------------------------------------

# Split diamonds data into separate training and test datasets
diamonds <- diamonds %>%
  sample_frac(1)              

train_v <- createDataPartition(y = diamonds$price, 
                               times = 1,
                               p = .1)

# Create separate training and test data

diamonds_train <- diamonds %>%
  slice(train_v$Resample1)

diamonds_test <- diamonds %>%
  slice(-train_v$Resample1)

# ---------------
# Explore
# ---------------

# Explore columns with summarizeColumns
skim(diamonds_train)

# Visualise relationships with ggpairs
ggpairs(diamonds_train)

# ---------------
# Step 1: Define control parameters
# ---------------

# Set up control values
ctr <- trainControl(method = "repeatedcv",
                    number = 10, # 10 folds
                    repeats = 2) # Repeat 2 times

# ---------------
# Step 2: Train model
# ---------------

# Predict price with linear regression
diamonds_lm_train <- train(form = price ~ ., 
                           data = diamonds_train,
                           method = "lm",
                           trControl = ctr)
# ---------------
# Step 3: Explore
# ---------------

class(diamonds_lm_train)
diamonds_lm_train
names(diamonds_lm_train)
summary(diamonds_lm_train)

# Look at variable importance with varImp
varImp(diamonds_lm_train)

# Look at final model object
diamonds_lm_train$finalModel

# ---------------
# Step 4: Predict
# ---------------

diamonds_lm_predictions <- predict(diamonds_lm_train, 
                                   newdata = diamonds_test)
# ---------------
# Step 5: Evaluate
# ---------------

# Look at final prediction performance!
postResample(pred = diamonds_lm_predictions, 
             obs = diamonds_test$price)

# Plot relationship between predictions and truth
performance_data <- tibble(predictions = diamonds_lm_predictions,
                          criterion = diamonds_test$price)

ggplot(data = performance_data,
       aes(x = predictions, y = criterion)) +
  geom_point(alpha = .1) +   # Add points
  geom_abline(slope = 1, intercept = 0, col = "blue", size = 2) +
  labs(title = "Regression prediction accuracy",
       subtitle = "Blue line is perfect prediction!")
```


A. Open your R project. It should already have the folders `0_Data` and `1_Code`. Make sure that the all of the datasets you need for this pradctical are in your `1_Data` folder

```{r}
# Done!
```

B. Open a new R script and save it as a new file called `ml_practical.R` in the `2_Code` folder. At the top of the script, using comments, write your name and the date. Then, load the all of the packages you'll need for this practical. Here's how the top of your script should look:

```{r, eval = FALSE, echo = TRUE}
## NAME
## DATE
## Machine Learning Practical

library(XX)     
library(XX)   
library(XX)   
```

### Modelling procedure

For each of the tasks, go through the following steps to 

A. Load the training data `XXX_train.csv` as a new dataframe called `XXX_train` and the test data `XXX_test.csv` as a new dataframe called `XXX_test`

B. Explore the `XXX_train` dataframe with a combination of `skim()`, `names()`, `summary()` and other similar functions

C. Define control parameters with `trainControl()`

D. Train one or more models on the training data. Start with one model, then gradually try more. For each model, assign the result to a new training object called `XX_train` (e.g.; `rf_train` for random forests, `glm_train` for standard regression.)

E. Explore your training objects by printing them, looking at (and printing) their named elements with `names()`, and viewing the final model with `XX_train$finalModel`

F. Predict the criterion values of the test data `XXX_test` using `predict()` and store the results in a vector called `XXX_pred` (e.g.; `rf_pred` for predictions from random forests)

G. Evaluate the model's prediction accuracy using `postResample()` and by creating an appropriate plot. 

### Models

Here are some models we recommend you try. If you'd like, you can try other ones from the list at [http://topepo.github.io/caret/available-models.html](http://topepo.github.io/caret/available-models.html)

<b>Regression Tasks</b>

*For classification tasks, your criterion should be numeric*

- Standard regression with `glm`
- Decision Trees with `rpart`
- Regularised regression with `glmnet`
- Random forests with `rf`

<b>Classification Tasks</b>

*For classification tasks, your criterion should be a factor*

- Decision Trees with `rpart`
- Random forests with `rf`
- K nearest neighbors with `knn`

## Tasks

#### Regression

1. Create your best possible model for the `house_train` dataset predicting housing `price`. Which model does the best in predicting `house_test$price`?

2. XXX

#### Classification

*Make sure your criterion values are factors!!*

3. Create your best possible model for the `heartdisease_train` dataset predicting `diagnosis`. Which model does the best in predicting `heartdisease_test$diagnosis?`

4. Create your best possible model for the `attrition_train` dataset predicting `attrition`. Which model does the best in predicting `attrition_test$attrition?`


### Tips

If you want to plot the results of multiple models, you can try using the following code template:

```{r, echo = TRUE, eval = TRUE}
# Some fake prediction data
#  include your real model prediction data here

XX_pred <- rnorm(100, mean = 100, sd = 10)
YY_pred <- rnorm(100, mean = 100, sd = 10)
ZZ_pred <- rnorm(100, mean = 100, sd = 10)

# Some fake true test values
#   Get these from your XX_test objects

truth <- rnorm(100, mean = 100, sd = 10)

# Put results together in a tibble

N <- length(truth)

model_results <- tibble(model = rep(c("XX", "YY", "ZZ"), each = N),
                        pred = c(XX_pred, YY_pred, ZZ_pred),
                        truth = rep(truth, times = 3))

# Add error and absolute error

model_results <- model_results %>%
  mutate(error = pred - truth,
         abserr = abs(error))

# Plot Distribution of errors for each model

ggplot(model_results, 
       aes(x = model, y = error, col = model)) +
  geom_jitter(width = .1, alpha = .5) +
  stat_summary(fun.y = mean, 
               fun.ymin = min, 
               fun.ymax = max, 
               colour = "black") + 
  labs(title = "Model Prediction Errors",
       subtitle = "Dots represent means",
       caption = "Caret is awesome!") +
  theme(legend.position = "none")


# Plot relationship between truth and predictions

ggplot(model_results, 
       aes(x = truth, y = pred, col = model)) +
  geom_point(alpha = .5) +
  geom_abline(slope = 1, intercept = 0) +
  labs(title = "XX model predictions",
       subtitle = "Diagonal represents perfect performance",
       caption = "Caret is awesome!",
       x = "True Values",
       y = "Model Predictions")
  
```









## house

In this task you'll predict the prices of houses in King County Washington. 

1. Load the `house_train.csv` data as a new dataframe called `house_train`

2. Explore




#### boston -- predicting median home value (medv)

The `boston` dataset contains housing data for 506 census tracts of Boston from the 1970 census. 

Here is a description of each of the variables in the dataset

| Column | Description|
|-----|-----------------------------------------|
|crim	|per capita crime rate by town|
|zn	|proportion of residential land zoned for lots over 25,000 sq.ft|
|indus	|proportion of non-retail business acres per town|
|chas	|Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)|
|nox	|nitric oxides concentration (parts per 10 million)|
|rm	|average number of rooms per dwelling|
|age	|proportion of owner-occupied units built prior to 1940|
|dis|	weighted distances to five Boston employment centres|
|rad|	index of accessibility to radial highways|
|tax|	full-value property-tax rate per USD 10,000|
|ptratio	|pupil-teacher ratio by town|
|b	|1000(B - 0.63)^2 where B is the proportion of blacks by town|
|lstat|	percentage of lower status of the population|
|medv|	median value of owner-occupied homes in USD 1000's|

### (E)xplore

1. Load the training data `boston_train.csv` into R as a new object with the name `boston_train` using `read_csv()`.

```{r, eval = FALSE, echo = FALSE}
boston_train <- read_csv("data/boston_train.csv")
```

2. Explore the data using the standard functions `head()`, `View()`, `names()` and `summary()`

3. Use the `summarizeColumns()` function from the `mlr` package to create numerical summaries of each column. Do you notice any strange columns?

```{r}
mlr::summarizeColumns(boston_train)
```

4. Can you think of a reason why you should remove any of the columns? If so, remove them using `select()`! There's no need to include unnecessary data in a machine learning algorithm :)

5. Visualise the data using the `ggpairs()` function from the `GGally` package. Do you notice any interesting patterns?

```{r}
ggpairs(boston_train)
```

### (T)rain

6. We will use 10-fold cross validation to train the models. To set up the fitting process, we'll need to use the `trainControl` function. Look at the help menu for this function and look through the examples to see how it works.

7. Using the `trainControl()` function, create an object called `rep10_control` that will conduct 10-fold cross validation.

```{r}
rep10_control <- caret::trainControl(method = "repeatedcv",
                                    number = 10,
                                    search = "grid")          # Find optimal parameters
```

8. We're almost ready to train models! To do so, we'll use the almighty `train()` function. Look at the help menu for the `train()` function to see all of its lovely arguments and examples.

9. Now it's time to actually train a model. We'll start with simple linear regression. Create an object called `boston_lm_train` where you predict a town's median home value `medv` based on all other variables. In order to conduct linear regression, include the arguments `method = 'lm'` and `trControl = rep10_control`

```{r}
boston_lm_train <- caret::train(form = medv ~ ., 
                                        data = boston_train,
                                        method = "lm",
                                        trControl = rep10_control)
```

10. Explore your `boston_lm_train` argument using the generic functions `names()`, `summary()`, and `plot()`. What is stored in this object?

11. Using the `varImp()` function, look at the variable importance of each predictor. Which predictors seem to be the most important? After you've run the function, try plotting the object with `plot()` to visualise the results!

```{r}
caret::varImp(boston_lm_train)
```

12. Load the test dataset as a new object called `boston_test` into R using `read_csv()`

13. Now it's time to make predictions form your model! Using `predict()`, predict the criterion values for the test dataset `boston_test`. In the `object` argument, use your `boston_lm_train` model, in the `newdata` argument, use your `boston_test` test data. Save the results as the vector `boston_lm_predictions`

```{r}
boston_lm_predictions <- predict(boston_lm_train, 
                                 newdata = boston_test)
```

### (E)valuate model performance

14. How well did your model do in predicting the true data? To start, plot the relationship between your model predictions and the true criterion using the following template

```{r, eval = FALSE, echo = TRUE}
# Combine predictions and criterion in one tibble
performance_data <- tibble(predictions = boston_lm_predictions,
                          criterion = boston_test$medv)

# Plot results
ggplot(data = performance_data,
       aes(x = predictions, y = criterion)) +
  geom_point() +   # Add points
  geom_abline(slope = 1, intercept = 0, col = "blue", size = 2) +
  labs(title = "Regression prediction accuracy",
       subtitle = "Blue line is perfect prediction!")
```

15. Now it's time to quantify how well your model did. To do this, we'll evaluate its performance with `postResample()`. Start by looking at the help menu for the `postResample()` function to see its arguments.

16. Now evaluate the model's predictions using `postResample()`. You should only specify the `pred` and `obs` arguments as `pred = boston_lm_predictions` and `obs = boston_test$medv`. 

```{r}
postResample(pred = boston_lm_predictions, 
             obs = boston_test$crim)
```

17. How well did your model do? What was the overall level of accuracy? If you don't understand the results, look at the details in the help menu for help!

## Ridge regression

18. Now let's try a new model! Instead of using simple linear regression with `method = 'lm'`, we'll use so--called 'ridge regression'. Ridge regression is a variation of 'standard' linear regression that tries to avoid overfitting and thus make better predictions. How can you use ridge regression in caret? Try to answer yourself by looking at the list of all available models on the caret help site: [http://topepo.github.io/caret/available-models.html](http://topepo.github.io/caret/available-models.html). Search for 'ridge' and find the `method` value.

19. Repeat steps 9 through 16 to create a *new* set of objects using ridge regression instead of standard linear regression.  When creating your objects, you may want to use the name `_ridge_` instead of `_regression_` so you know which object is which!. As you are creating your new objects, make sure to stop and explore them (i.e.; with `summary()`, `plot()`, `print()` to see how they look different from the previous objects. 

20. Which model predicted the data better? Standard regression or ridge regression? Was using ridge regression able to improve your predictions?

## Random forests

21. Now you're getting the hang of it! Instead of regression, let's try a totally different model....random forests! Repeat all of your steps to see how well random forests do in predicting the `boston_test` data.

# heartdisease - Predicting heartdisease status

Now it's time to try a classification problem. We'll do this with the `heartdisease` data. The `heartdisease` dataset contains data from 303 patients suspected of having heart disease The objective is to predict the `diagnosis` column indicating whether a patient has heartdisease or not

Here is a description of each of the variables in the dataset

| Column | Description|
|-----|-----------------------------------------|
|age | Age |
|sex|Sex, 1 = male, 0 = female|
|cp| Chest pain type: ta = typical angina, aa = atypical angina, np = non-anginal pain, a = asymptomatic|
|trestbps| Resting blood pressure (in mm Hg on admission to the hospital)|
|chol |Serum cholestoral in mg/dl |
|fbs |Fasting blood sugar > 120 mg/dl: 1 = true, 0 = false|
|restecg |Resting electrocardiographic results. "normal" = normal, "abnormal" = having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV), "hypertrophy" = showing probable or definite left ventricular hypertrophy by Estes' criteria.|
|thalach| Maximum heart rate achieved|
|exang| Exercise induced angina: 1 = yes, 0 = no|
|oldpeak |ST depression induced by exercise relative to rest|
|slope |The slope of the peak exercise ST segment.|
|ca| Number of major vessels (0-3) colored by flourosopy|
|thal| "normal" = normal, "fd" = fixed defect, "rd" = reversible defect|
|diagnosis| 1 = Heart disease, 0 = No Heart disease|

22. Load the training data `heartdisease_train.csv` into R as a new object with the name `heartdisease_train` using `read_csv()`.

```{r, eval = FALSE}
heartdisease_train <- read_csv("data/heartdisease_train.csv")
```

23. Before you do anything else, convert the `diagnosis` column to a factor. This will be necessary for some machine learning models to work!

```{r, eval = FALSE, echo = TRUE}
# Convert diagnosis to a factor
#   This is important for some machine learning models to do
#   classification analyses

heartdisease_train <- heartdisease_train %>%
  mutate(diagnosis = factor(diagnosis))      # Convert diagnosis to a factor

```


23. Follow tasks 2 - 5 to explore the data. Remember our goal is to predict `diagnosis`!

24. Now it's time to train a model on the data. For this data, we can't use linear regression because the criterion is a nominal class. Instead, we'll start with a type of decision tree called CART. Look at [http://topepo.github.io/caret/available-models.html](http://topepo.github.io/caret/available-models.html) to find the correct method for using CART.

```{r}
heartdisease_rpart_train <- caret::train(form = diagnosis ~ ., 
                                        data = heartdisease_train,
                                        method = "rpart",
                                        trControl = rep10_control)

heartdisease_rpart_predictions <- predict(heartdisease_rpart_train, newdata = heartdisease_test)
```


25. Follow tasks 6 - 17 to fit your model, and evaluate its performance. 
    - When you read in the `heartdisease_test` data, make sure to convert the `diagnosis` column to a factor like you did for the `heartdisease_train` data.
    - In task 14, where you try to visualise the performance of the model, you'll need to tweak the plotting code a bit. To help, try using the following code template:

```{r, eval = FALSE, echo = TRUE}
# -----------------------------------------------------------
# Visualise the relationship between two nominal variables
# -----------------------------------------------------------

# Combine predictions and criterion in one tibble
performance_data <- tibble(predictions = heartdisease_rpart_predictions,
                          criterion = heartdisease_test$diagnosis)

# Plot results
ggplot(data = performance_data, 
       aes(x = predictions, ..count..)) + 
  geom_bar(aes(fill = criterion), position = "dodge") +
  labs(title = "CART prediction accuracy")
```

```{r}
postResample(pred = heartdisease_rpart_predictions, 
             obs = factor(heartdisease_test$diagnosis))
```

26. Now that you've fit CART, try using random forests! How well do random forests compare to plain old decision trees with CART?

27. If you've gotten this far, then you've really gotten the hang of the package! Try exploring the list of all models available in `caret` (again check out [http://topepo.github.io/caret/available-models.html](http://topepo.github.io/caret/available-models.html) to see them all). Look for the craziest looking models you can find, and see how well they do on the two datasets in this practical. Can you find one that does much better than regression, random forests, or decision trees?

### Further Reading

- Max Kuhn, the author of `caret` has a fantastic overview of the package at [http://topepo.github.io/caret/index.html](http://topepo.github.io/caret/index.html). If you like the `caret` package as much as we do, be sure to go through this page in detail.

- Max Kuhn is also the co-author of a fantastic book on machine learning called [Applied predictive modelling - http://appliedpredictivemodeling.com/](http://appliedpredictivemodeling.com/).
 